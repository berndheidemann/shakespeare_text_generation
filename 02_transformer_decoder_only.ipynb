{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us\n"
     ]
    }
   ],
   "source": [
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65, 27, 46, 1, 24, 53, 56, 42]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_token = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "SOS_TOKEN = '#'\n",
    "\n",
    "assert SOS_TOKEN not in token_to_idx\n",
    "\n",
    "token_to_idx[SOS_TOKEN] = vocab_size\n",
    "idx_to_token[vocab_size] = SOS_TOKEN\n",
    "\n",
    "vocab_size += 1\n",
    "\n",
    "def encode(text):\n",
    "    return [token_to_idx.get(ch, 0) for ch in text]\n",
    "\n",
    "def decode(text_encoded):\n",
    "    return ''.join([idx_to_token.get(i, '') for i in text_encoded])\n",
    "\n",
    "encode(\"#Oh Lord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Oh Lord'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([65, 27, 46, 1, 24, 53, 56, 42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
       "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
       "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
       "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
       "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
       "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
       "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
       "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
       "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
       "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
       "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
       "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([65, 18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,\n",
      "        44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52,\n",
      "        63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,\n",
      "         1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39,\n",
      "        49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15,\n",
      "        47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50,\n",
      "        50,  1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1,\n",
      "        58, 53], device='cuda:0'), tensor([47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44, 53,\n",
      "        56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,  1,\n",
      "        44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1, 57,\n",
      "        54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,  6,\n",
      "         1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,  1,\n",
      "        56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58, 53,\n",
      "         1, 42], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#device=torch.device('cpu')\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, seq_len, block_size=128):\n",
    "        self.data = data.to(device)\n",
    "        self.seq_len = seq_len\n",
    "        self.block_size = block_size\n",
    "        self.sos_token = torch.tensor([token_to_idx[SOS_TOKEN]], dtype=torch.long).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data) - self.seq_len) // self.block_size\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = self.data[i * self.block_size: ((i + 1) * self.block_size)-1]\n",
    "        x = torch.cat([self.sos_token, x])\n",
    "        y = self.data[i * self.block_size + 1: (i + 1) * self.block_size + 1]\n",
    "        return x, y\n",
    "    \n",
    "seq_len = 768\n",
    "train_ds = Dataset(train_data, seq_len)\n",
    "val_ds = Dataset(val_data, seq_len)\n",
    "\n",
    "print(train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "mask of size: 128\n",
      "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "torch.Size([32, 128, 66])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, nhead=128, num_layers=3):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim)\n",
    "        self.transformer_layer = torch.nn.TransformerDecoderLayer(d_model=embedding_dim, nhead=nhead, batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(self.transformer_layer, num_layers=num_layers)\n",
    "        self.fc = torch.nn.Linear(embedding_dim, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, torch.nn.ConvTranspose2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "                torch.nn.init.ones_(m.weight)\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, torch.nn.LayerNorm):\n",
    "                torch.nn.init.ones_(m.weight)\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, src, mask=None):\n",
    "        src = self.embedding(src) * math.sqrt(self.embedding_dim)\n",
    "        src = self.pos_encoder(src)\n",
    "        # Da es sich um ein Decoder-only Modell handelt, ist `memory` nicht notwendig.\n",
    "        # Stattdessen verwenden wir `src` direkt als Eingabe f端r den Transformer Decoder.\n",
    "        out = self.transformer_decoder(src, memory=src, tgt_mask=mask)\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"Generiert eine obere Dreiecksmatrix zur Maskierung der zuk端nftigen Tokens.\"\"\"\n",
    "    mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "model = SimpleModel(vocab_size, 128).to(device)\n",
    "train_loader=torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "for xb, yb in train_loader:\n",
    "    print(xb.shape)\n",
    "    print(\"mask of size:\", xb.size(1))\n",
    "    mask=generate_square_subsequent_mask(xb.size(1)).to(device)\n",
    "    print(mask)\n",
    "    out = model(xb, mask=mask)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh LordATz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(model, text, length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Initialisieren Sie die Eingabe mit einem Start-Token oder der kodierten Eingabe\n",
    "        input_data = torch.tensor(encode(text), dtype=torch.long, device=device).unsqueeze(0)\n",
    "        \n",
    "        # Bereiten Sie eine leere Sequenz f端r die Decoder-Eingabe vor (oder verwenden Sie ein SOS-Token)\n",
    "\n",
    "        for i in range(length):\n",
    "            # Verwenden Sie die aktuelle Decoder-Eingabe f端r die Vorhersage\n",
    "            mask=generate_square_subsequent_mask(input_data.size(1)).to(device)\n",
    "            out = model(input_data, mask=mask)\n",
    "            last_token_logits = out[:, -1, :]\n",
    "            last_token_prob = torch.softmax(last_token_logits, dim=-1)\n",
    "            \n",
    "            # print top 5 tokens\n",
    "            #values, indices = torch.topk(last_token_prob, 5)\n",
    "            #for v, i in zip(values[0], indices[0]):\n",
    "            #    print(f\"{decode([i.item()])} ({v.item():.4f})\", end=\", \")\n",
    "            #print()\n",
    "            #print(torch.argmax(last_token_prob, dim=1).unsqueeze(1))\n",
    "            predicted_token = torch.argmax(last_token_prob, dim=1).unsqueeze(1)\n",
    "            \n",
    "            # Aktualisieren Sie die Decoder-Eingabe mit dem neu vorhergesagten Token\n",
    "            input_data = torch.cat([input_data, predicted_token], dim=1)\n",
    "    return decode(input_data.cpu().numpy()[0])  \n",
    "\n",
    "generate_text(model, \"Oh Lord\", 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 3.2851047977324455, val_loss: 2.991214394569397, correct predicted: 22918, sample_output: Oh Lor o o o o o o o \n",
      "Epoch 2, train_loss: 2.977508529540031, val_loss: 2.9313393235206604, correct predicted: 23201, sample_output: Oh Lor e e e e e e e \n",
      "Epoch 4, train_loss: 2.9338382751710954, val_loss: 2.9184478521347046, correct predicted: 23341, sample_output: Oh Lor e e o e o e e \n",
      "Epoch 6, train_loss: 2.9071459308747323, val_loss: 2.9094192385673523, correct predicted: 23327, sample_output: Oh Lor o o o o o o o \n",
      "Epoch 8, train_loss: 2.8880800739411385, val_loss: 2.904467821121216, correct predicted: 23387, sample_output: Oh Lor o o o o o o o \n",
      "Epoch 10, train_loss: 2.8765700786344466, val_loss: 2.8994768857955933, correct predicted: 23410, sample_output: Oh Lor o o o o o o o \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m---> 46\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_loader, loss_func, optimizer)\u001b[0m\n\u001b[0;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 23\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "model = SimpleModel(vocab_size, embedding_dim=512, nhead=16, num_layers=1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def train_epoch(model, train_loader, loss_func, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        mask=generate_square_subsequent_mask(xb.size(1)).to(device)\n",
    "        y_pred = model(xb, mask=mask)\n",
    "       \n",
    "        loss = loss_func(y_pred.view(-1, vocab_size), yb.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss/len(train_loader)\n",
    "\n",
    "def validate_epoch(model, val_loader, loss_func):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            mask=generate_square_subsequent_mask(yb.size(1)).to(device)\n",
    "            y_pred = model(xb, mask=mask)\n",
    "            loss = loss_func(y_pred.view(-1, vocab_size), yb.view(-1))\n",
    "            total_loss += loss.item()\n",
    "            correct += (torch.argmax(y_pred, dim=2) == yb).sum().item()\n",
    "    return total_loss/len(val_loader), correct\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader=torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for i in range(1000):\n",
    "    train_loss = train_epoch(model, train_loader, loss_func, optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    if i % 2 == 0:\n",
    "        val_loss, acc = validate_epoch(model, val_loader, loss_func)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch {i}, train_loss: {train_loss}, val_loss: {val_loss}, correct predicted: {acc}, sample_output:', generate_text(model, \"Oh Lor\", 15))\n",
    "    else:\n",
    "        val_losses.append(val_losses[-1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[39]], device='cuda:0')\n",
      "tensor([[39]], device='cuda:0')\n",
      "tensor([[39]], device='cuda:0')\n",
      "tensor([[39]], device='cuda:0')\n",
      "tensor([[39]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aaaaa'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, 'Thank you! qw ', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'eeeee'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, \"This is a strange repose, to be asleep With eyes wide open; standing, speaking, moving,\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.17242780793458223, val_loss: 0.12128036469221115\n",
      "Epoch 10, train_loss: 0.10837701428681612, val_loss: 0.07178276032209396\n",
      "Epoch 20, train_loss: 0.07412474183365703, val_loss: 0.0466329213231802\n",
      "Epoch 30, train_loss: 0.05364865646697581, val_loss: 0.032324107363820076\n",
      "Epoch 40, train_loss: 0.04040246014483273, val_loss: 0.023512743413448334\n",
      "Epoch 50, train_loss: 0.03169565834105015, val_loss: 0.01773807965219021\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[51], line 18\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_loader, loss_func, optimizer)\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 18\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    train_loss = train_epoch(model, train_loader, loss_func, optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    if i % 10 == 0:\n",
    "        val_loss = validate_epoch(model, val_loader, loss_func)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch {i}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    else:\n",
    "        val_losses.append(val_losses[-1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n",
      "tensor([[43]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, 'Thank you', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a strange repose, to be asleep With eyes wide open; standing, speaking, moving,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, \"This is a strange repose, to be asleep With eyes wide open; standing, speaking, moving,\", 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
